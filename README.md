# ğŸŒ«ï¸ Object Detection in Hazy and Foggy Conditions on NVIDIA Jetson Nano

## ğŸ“˜ Project Overview
This repository contains the **Phase 1: Literature Review & Feasibility** work for the research project conducted at the **School of Electrical Engineering and Computer Science (SEECS), National University of Sciences and Technology (NUST), Islamabad, Pakistan**.  
The study focuses on enhancing **object detection under haze and fog** using **lightweight deep-learning models** optimized for deployment on **NVIDIA Jetson Nano (4 GB)** embedded hardware.

The project explores how modern dehazing-aware detection architecturesâ€”such as **AOD-YOLOv5s**, **TSMD-Net**, **YOLOv5s-Fog**, and **IDOD-YOLOv7**â€”achieve real-time inference and high detection accuracy despite limited compute resources.

---

## ğŸ‘¥ Authors
- **Wassi Haider Kabir**  
- **Muhammad Ashar Javid**  
- **Hamza Irshad Bhatti**  
- **Ammar**  
School of Electrical Engineering and Computer Science (SEECS)  
National University of Sciences and Technology (NUST), Islamabad, Pakistan  

---

## ğŸ§  Research Summary
The literature review consolidates research from **2019â€“2025** on haze/fog detection, highlighting:
- **AOD-YOLOv5s (Li et al., 2024)** â€” Hybrid dehazing and YOLOv5 integration with 76.8 % mAP, 42 % parameter reduction.  
- **TSMD-Net (Raju & Srinivas, 2024)** â€” Dual-attention dehazing network validated on Jetson Nano (16.3 M params, 1.9 s per frame).  
- **YOLOv5s-Fog (Meng et al., 2023)** â€” Swin-Transformer attention improving mAP + 5.4 %.  
- **IDOD-YOLOv7 (Qiu et al., 2023)** â€” SAIP-based joint enhancement and detection network achieving +7.9 % mAP and 71 FPS.

All reviewed models maintain < 70 GFLOPs and < 20 M parameters, confirming feasibility for **Jetson Nano** deployment with FP16/INT8 quantization.

---

## âš™ï¸ Repository Structure
ğŸ“ /docs
â”œâ”€â”€ Literature_Review_Phase1.pdf # Final IEEE-formatted review
â”œâ”€â”€ Feasibility_Summary.txt # Jetson Nano deployment notes
â””â”€â”€ references/ # Verified cited papers (PDFs/links)

ğŸ“ /src
â””â”€â”€ (Phase 2 implementation â€“ to be added)

ğŸ“ /results
â””â”€â”€ (future inference benchmarks)


---

## ğŸ” Key Highlights
- âœ… Comprehensive IEEE-formatted **literature review** (2019â€“2025)  
- ğŸ§  Focus on **joint dehazing and object detection** under adverse weather  
- âš™ï¸ Verified feasibility on **Jetson Nano 4 GB**  
- ğŸ“š Repository includes **verified papers and sources**  
- ğŸš€ Ready foundation for **Phase 2 implementation & benchmarking**

---

## ğŸ“š Verified References
| No. | Paper | Source |
|----:|-------|--------|
| [1] | **Qiu et al. (2023)** â€“ *IDOD-YOLOv7: Image-Dehazing YOLOv7 for Object Detection in Low-Light Foggy Traffic Environments* | *Sensors 23 (13): 1347* |
| [2] | **Li et al. (2024)** â€“ *Object Detection in Hazy Environments Based on an All-in-One Dehazing Network and YOLOv5* | *Electronics 13 (1862)* |
| [3] | **Raju & Srinivas (2024)** â€“ *TSMD-Net: Two-Stage Mixed Dehazing Network* | *Digital Signal Processing 155 (104710)* |
| [4] | **Meng et al. (2023)** â€“ *YOLOv5s-Fog: An Improved Model for Object Detection in Foggy Weather* | *Sensors 23 (11): 5321* |

---

## ğŸ’» Hardware Feasibility (Jetson Nano 4 GB)
| Parameter | Specification |
|------------|----------------|
| GPU | 128-core Maxwell GPU |
| RAM | 4 GB LPDDR4 |
| Target Models | YOLOv5s-Fog, IDOD-YOLOv7 |
| Precision | FP16 / INT8 (TensorRT optimized) |
| Target FPS | 10â€“15 FPS |
| Power | 5 V â“ 4 A |

---

## ğŸ§¾ Mandatory Declaration
> ChatGPT (Deep Research Mode) was used to search, verify, and summarize peer-reviewed research papers and generate the narrative literature review.  
> All sources were opened and confirmed by the team.  
> Verified papers are available in the `/docs/references/` folder.

---

## ğŸ§© Future Work (Phase 2)
- Implement selected dehazingâ€“detection pipelines (IDOD-YOLOv7 / AOD-YOLOv5).  
- Quantize and deploy on **Jetson Nano 4 GB** using TensorRT.  
- Record FPS, mAP, and power consumption under fog simulation.  
- Publish comparative results in `/results/`.

